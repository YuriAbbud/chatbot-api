# Modelo Ollama a ser utilizado
LLM_MODEL_NAME = "llama3.2:1b"

# Tamanho máximo para cache local armazenar perguntas e respostas recentes
CACHE_MAX_SIZE = 100

# Tamanho máximo para histórico de chat
HISTORY_MAX_SIZE = 200

# Arquivo de logs
LOG_FILENAME = "log.log"